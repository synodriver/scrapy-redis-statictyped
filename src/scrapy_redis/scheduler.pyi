from redis import Redis
from scrapy import Request as Request, Spider as Spider
from scrapy.crawler import Crawler as Crawler
from scrapy.settings import Settings as Settings
from types import ModuleType
from typing import Any, Optional

class Scheduler:
    server: Any = ...
    persist: Any = ...
    flush_on_start: Any = ...
    queue_key: Any = ...
    queue_cls: Any = ...
    dupefilter_cls: Any = ...
    dupefilter_key: Any = ...
    idle_before_close: Any = ...
    serializer: Any = ...
    stats: Any = ...
    queue: Any = ...
    df: Any = ...
    def __init__(self, server: Redis, persist: Optional[bool]=..., flush_on_start: Optional[bool]=..., queue_key: Optional[str]=..., queue_cls: Optional[str]=..., dupefilter_key: Optional[str]=..., dupefilter_cls: Optional[str]=..., idle_before_close: Optional[int]=..., serializer: Optional[ModuleType]=...) -> None: ...
    def __len__(self) -> int: ...
    @classmethod
    def from_settings(cls: Any, settings: Settings) -> Scheduler: ...
    @classmethod
    def from_crawler(cls: Any, crawler: Crawler) -> Any: ...
    spider: Any = ...
    def open(self, spider: Spider) -> None: ...
    def close(self, reason: Any) -> None: ...
    def flush(self) -> None: ...
    def enqueue_request(self, request: Request) -> bool: ...
    def next_request(self) -> Request: ...
    def has_pending_requests(self) -> bool: ...
